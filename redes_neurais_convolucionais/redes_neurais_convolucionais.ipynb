{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W0JSA7WyST3"
      },
      "source": [
        "# Redes Neurais Convolucionais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BGseAaqBhOx"
      },
      "source": [
        "### Descriçao\n",
        "\n",
        "---\n",
        "1. O objetivo deste notebook é Redes Neurais Convolucionais.\n",
        "2. Os dados para usar serão clonados do nosso próprio github, pela pasta dataset.\n",
        "3. Vamos treinar nosso modelo para que ele aprenda a detectar doença em plantações de tomate.\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4GkP4zAB5D6"
      },
      "source": [
        "# Instalação de pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vcmBuoIs0Qrk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88c48cb5-6546-47d7-cdc6-5a66249daa03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio pandas numpy keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KVRo2QhCMpE"
      },
      "source": [
        "# Obtendo o dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kJgY2Sd60_x2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56fa924c-e41c-4c97-b97b-52b823a3e65e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'coding_the_future_dio_redes_neurais'...\n",
            "remote: Enumerating objects: 11037, done.\u001b[K\n",
            "remote: Counting objects: 100% (105/105), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 11037 (delta 50), reused 74 (delta 24), pack-reused 10932 (from 1)\u001b[K\n",
            "Receiving objects: 100% (11037/11037), 196.13 MiB | 29.36 MiB/s, done.\n",
            "Resolving deltas: 100% (73/73), done.\n",
            "Updating files: 100% (11028/11028), done.\n"
          ]
        }
      ],
      "source": [
        "# Clona o repositório do GitHub contendo o material necessário\n",
        "!git clone https://github.com/batestin1/coding_the_future_dio_redes_neurais.git\n",
        "\n",
        "# Move apenas a pasta 'dataset' para o diretório atual ('/content/')\n",
        "!mv coding_the_future_dio_redes_neurais/dataset /content/\n",
        "\n",
        "# Remove o restante do repositório, já que não será mais utilizado\n",
        "!rm -rf coding_the_future_dio_redes_neurais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igTRMPADEQ6p"
      },
      "source": [
        "# Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "J-Y0HTwLyUtt"
      },
      "outputs": [],
      "source": [
        "# Importa o NumPy para criação e manipulação de matrizes\n",
        "import numpy as np\n",
        "\n",
        "# Importa o módulo OS para manipulação de pastas e arquivos\n",
        "import os\n",
        "\n",
        "# Importa as bibliotecas necessárias do Keras para construção da rede neural\n",
        "from keras.models import Sequential          # Para iniciar o modelo sequencial da rede neural\n",
        "from keras.layers import Conv2D               # Camada de convolução (extração de características)\n",
        "from keras.layers import MaxPooling2D         # Camada de max pooling (redução de dimensionalidade)\n",
        "from keras.layers import Flatten              # Camada de flatten (transformação dos dados para a camada densa)\n",
        "from keras.layers import Dense                # Camada densa (camada totalmente conectada)\n",
        "from keras.layers import Dropout              # Camada de dropout (redução de overfitting)\n",
        "\n",
        "from keras.preprocessing import image         # Para carregar e testar imagens manualmente\n",
        "\n",
        "from keras.layers import Rescaling             # Para normalizar os valores dos pixels (RGB entre 0 e 1)\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # CORRETO: Para o pré-processamento e aumento de imagens (data augmentation)\n",
        "\n",
        "from tensorflow.keras.utils import plot_model  # Para visualizar a arquitetura do modelo\n",
        "\n",
        "from keras.models import load_model            # Para salvar e carregar modelos treinados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqnN4z8OEzym"
      },
      "source": [
        "# Construindo a RNC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SZWXBuX3FEa8"
      },
      "outputs": [],
      "source": [
        "# Inicializando a rede neural convolucional (CNN) com o modelo sequencial\n",
        "rnc = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Q9N0b2PKKOqL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1e32d8b-e170-4124-8a81-c5e26d65fa70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Criando Camadas Convolucionais\n",
        "\n",
        "# Adiciona uma camada de pré-processamento para normalizar os valores dos pixels (de 0 a 255 para 0 a 1)\n",
        "rnc.add(Rescaling(scale=1.0/255))\n",
        "\n",
        "# Adiciona a primeira camada convolucional\n",
        "# Conv2D(32, (3, 3)) -> 32 filtros (detectores de características), cada um de tamanho 3x3\n",
        "# input_shape -> Formato da imagem de entrada: 128x128 pixels e 3 canais (RGB)\n",
        "# activation='relu' -> Função de ativação ReLU (Rectified Linear Unit)\n",
        "rnc.add(Conv2D(32, (3, 3), input_shape=(128, 128, 3), activation='relu'))\n",
        "\n",
        "# Adiciona a primeira camada de MaxPooling\n",
        "# Reduz a dimensionalidade da imagem (pooling de 2x2) preservando as características principais\n",
        "rnc.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Adiciona a segunda camada convolucional\n",
        "# 16 filtros de 3x3 e função de ativação ReLU\n",
        "rnc.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "\n",
        "# Adiciona a segunda camada de MaxPooling\n",
        "rnc.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Adiciona a terceira camada convolucional\n",
        "# 8 filtros de 3x3 e função de ativação ReLU\n",
        "rnc.add(Conv2D(8, (3, 3), activation='relu'))\n",
        "\n",
        "# Adiciona a terceira camada de MaxPooling\n",
        "rnc.add(MaxPooling2D(pool_size=(2, 2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vTVPMCVEE54T"
      },
      "outputs": [],
      "source": [
        "# Flattening\n",
        "\n",
        "# A camada Flatten \"achata\" (flatten) a matriz 3D de saída das camadas convolucionais e de pooling\n",
        "# Transforma em um vetor 1D para poder ser usado nas camadas densas (camadas totalmente conectadas)\n",
        "rnc.add(Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wRvffSYAF45Q"
      },
      "outputs": [],
      "source": [
        "# Full Connect (Camadas totalmente conectadas)\n",
        "\n",
        "# Adicionando uma camada densa (fully connected)\n",
        "# 128 neurônios, todos conectados com a camada anterior (Flatten)\n",
        "# Função de ativação ReLU para adicionar não-linearidade\n",
        "rnc.add(Dense(units=128, activation='relu'))\n",
        "\n",
        "# Adicionando uma camada de Dropout\n",
        "# Durante o treinamento, \"desliga\" 50% dos neurônios aleatoriamente\n",
        "# Isso ajuda a evitar overfitting (modelo aprender demais os dados de treino)\n",
        "rnc.add(Dropout(rate=0.5))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Camada de Saída (Output Layer)\n",
        "\n",
        "# Adicionando uma camada densa com 10 unidades (neurônios)\n",
        "# Cada unidade corresponde a uma classe de saída (supondo 10 classes)\n",
        "# Função de ativação softmax para gerar probabilidades (valores entre 0 e 1 que somam 1)\n",
        "rnc.add(Dense(units=10, activation='softmax'))"
      ],
      "metadata": {
        "id": "hBkar9yguW_J"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WHbun15XGGnp"
      },
      "outputs": [],
      "source": [
        "# Compilando a rede neural\n",
        "\n",
        "# Define o otimizador que ajustará os pesos da rede durante o treinamento (Adam é uma escolha popular por ser eficiente)\n",
        "# Define a função de perda (loss function) usada para calcular o erro — categorical_crossentropy é apropriado para problemas de múltiplas classes (10 classes aqui)\n",
        "# Define as métricas que queremos acompanhar durante o treinamento — no caso, a acurácia\n",
        "rnc.compile(\n",
        "  optimizer='adam',                 # Otimizador Adam\n",
        "  loss='categorical_crossentropy',   # Função de perda para classificação multiclasse\n",
        "  metrics=['accuracy']               # Métrica de avaliação: acurácia\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPcB-Y_FFIym"
      },
      "source": [
        "# Pré-processamento das imagens\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6Cb-DftGqd3"
      },
      "source": [
        "#### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4Sn3RPEEFKge"
      },
      "outputs": [],
      "source": [
        "# Criando um gerador de imagens para treinamento\n",
        "# O ImageDataGenerator aplica transformações nas imagens para aumentar a variedade do dataset (data augmentation)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "  shear_range=0.2,        # Aplica distorções aleatórias (cisalhamento) nas imagens\n",
        "  zoom_range=0.2,         # Aplica zoom aleatório nas imagens\n",
        "  horizontal_flip=True    # Inverte as imagens horizontalmente de forma aleatória\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1ZYfedtYGhat"
      },
      "outputs": [],
      "source": [
        "# Criando um gerador de imagens para teste\n",
        "# No conjunto de teste, normalmente só normalizamos as imagens, sem data augmentation\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "  rescale=1./255  # Normaliza os valores dos pixels para o intervalo [0, 1]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Z9INdBGaGi7l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8782600a-2765-40d6-eeaf-e6e002c7c28a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "# Cria o conjunto de treinamento a partir das imagens no diretório especificado\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "  '/content/dataset/rnc/train',  # Caminho onde estão as imagens de treino organizadas por pastas (uma pasta por classe)\n",
        "  target_size=(128, 128),        # Redimensiona todas as imagens para 128x128 pixels\n",
        "  batch_size=128,                # Número de imagens carregadas por vez (batch)\n",
        "  class_mode='categorical'       # Tipo de classificação: múltiplas classes (one-hot encoding)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IX2rsc8AGnip"
      },
      "outputs": [],
      "source": [
        "# Visualiza o mapeamento das classes (índices das classes) identificadas no conjunto de treinamento\n",
        "label_map = (training_set.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yNlKt6neGpJg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f9c653-ea67-446c-eea9-02b4f9d81cb2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Bacterial_spot': 0,\n",
              " 'Early_blight': 1,\n",
              " 'Late_blight': 2,\n",
              " 'Leaf_Mold': 3,\n",
              " 'Septoria_leaf_spot': 4,\n",
              " 'Spider_mites Two-spotted_spider_mite': 5,\n",
              " 'Target_Spot': 6,\n",
              " 'Tomato_Yellow_Leaf_Curl_Virus': 7,\n",
              " 'Tomato_mosaic_virus': 8,\n",
              " 'healthy': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "label_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfjzqIYHGsaX"
      },
      "source": [
        "#### Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tdVrNjfAGt5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcae2f0e-05fa-4a07-8960-0a5d809c926b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "# Carrega o conjunto de teste\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "  '/content/dataset/rnc/test',   # Caminho da pasta que contém as imagens de teste organizadas por classe\n",
        "  target_size=(128, 128),         # Redimensiona todas as imagens para 128x128 pixels\n",
        "  batch_size=128,                 # Número de imagens carregadas por vez\n",
        "  class_mode='categorical')       # Tipo de classificação (multiclasse, cada imagem pertence a uma única classe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qHym1KNFcgT"
      },
      "source": [
        " # Treinando A Rede Neural"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinando a rede neural convolucional (forma atualizada)\n",
        "rnc.fit(\n",
        "  training_set,          # Dados de treino\n",
        "  steps_per_epoch=1,     # Número de lotes de imagens por época\n",
        "  epochs=4,              # Número de épocas\n",
        "  validation_data=test_set,  # Dados de validação\n",
        "  validation_steps=1     # Número de lotes de validação por época\n",
        ")"
      ],
      "metadata": {
        "id": "D_IHF4CPv0zI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e2fdf32-1325-4bba-858f-b166df357c5a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step - accuracy: 0.0938 - loss: 2.3042 - val_accuracy: 0.0781 - val_loss: 2.3026\n",
            "Epoch 2/4\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 0.1406 - loss: 2.2947 - val_accuracy: 0.0938 - val_loss: 2.3024\n",
            "Epoch 3/4\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 0.0938 - loss: 2.2901 - val_accuracy: 0.0391 - val_loss: 2.3032\n",
            "Epoch 4/4\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.0859 - loss: 2.3066 - val_accuracy: 0.0859 - val_loss: 2.3026\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cf15c118790>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### avaliação do modelo"
      ],
      "metadata": {
        "id": "qAgvRsm-iX_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliando o modelo no conjunto de teste\n",
        "\n",
        "# 'evaluate' calcula a loss (erro) e a acurácia no conjunto de teste\n",
        "test_loss, test_accuracy = rnc.evaluate(\n",
        "  test_set,     # dados de teste\n",
        "  steps=50      # número de batches para avaliação (ajustar conforme o tamanho do dataset)\n",
        ")\n",
        "\n",
        "# Exibe a loss (erro) no conjunto de teste\n",
        "print(f'Test loss: {test_loss}')\n",
        "\n",
        "# Exibe a acurácia no conjunto de teste\n",
        "print(f'Test accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "id": "sBn6gaP7iJYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40af4e2c-49c6-4329-d2c0-e2e57b51612f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.1014 - loss: 2.3030  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 2.303351879119873\n",
            "Test accuracy: 0.10000000149011612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testando a performance"
      ],
      "metadata": {
        "id": "NzIU-vDYiwdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando as classes identificadas no conjunto de treinamento\n",
        "label_map.keys()"
      ],
      "metadata": {
        "id": "SmXrByGVkx4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba18aba1-8acd-4e4d-91bb-12b9379990b5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['Bacterial_spot', 'Early_blight', 'Late_blight', 'Leaf_Mold', 'Septoria_leaf_spot', 'Spider_mites Two-spotted_spider_mite', 'Target_Spot', 'Tomato_Yellow_Leaf_Curl_Virus', 'Tomato_mosaic_virus', 'healthy'])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar uma imagem para fazer a previsão\n",
        "img_path = '/content/dataset/rnc/test/Bacterial_spot/01a3cf3f-94c1-44d5-8972-8c509d62558e___GCREC_Bact.Sp 3396.JPG'\n",
        "\n",
        "# Carrega a imagem e redimensiona para o tamanho usado no treinamento\n",
        "img = image.load_img(img_path, target_size=(128, 128))\n",
        "\n",
        "# Converte a imagem para um array NumPy\n",
        "img_array = image.img_to_array(img)\n",
        "\n",
        "# Adiciona uma dimensão extra para simular um \"batch\" (lote de imagens)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Normaliza os pixels para o intervalo [0, 1]\n",
        "img_array /= 255.0\n",
        "\n",
        "# Faz a previsão usando o modelo treinado\n",
        "prediction = rnc.predict(img_array)\n",
        "\n",
        "# Obtém o índice da classe com a maior probabilidade\n",
        "predicted_class = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "# Cria um dicionário invertido para mapear índice para nome da classe\n",
        "inverse_label_map = {v: k for k, v in label_map.items()}\n",
        "\n",
        "# Usa o índice para buscar o nome da classe\n",
        "predicted_class_name = inverse_label_map[predicted_class]\n",
        "\n",
        "# Imprime o nome da classe predita (removendo alguns termos para deixar mais limpo)\n",
        "print(f\"A imagem é: {predicted_class_name.replace('_', ' ').replace('Tomato', '').replace(' ', '')}\")"
      ],
      "metadata": {
        "id": "_DrIwBXRiivn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dedb6e28-599b-4a8a-8b1a-1da3846fb9a3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
            "A imagem é: YellowLeafCurlVirus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfEQ3UWlGzmv"
      },
      "source": [
        "# Salvando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "X3iJRuC5G1Ek"
      },
      "outputs": [],
      "source": [
        "# Define o nome da pasta onde o modelo será salvo\n",
        "folder = 'rnc/'\n",
        "\n",
        "# Verifica se o diretório existe; se não existir, cria o diretório\n",
        "if not os.path.exists(folder):\n",
        "  os.makedirs(folder)\n",
        "\n",
        "# Salva apenas os pesos da rede neural convolucional no diretório especificado\n",
        "rnc.save_weights(os.path.join(folder, 'rede_neural_convolucional.weights.h5'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0W0JSA7WyST3",
        "6KVRo2QhCMpE",
        "CfEQ3UWlGzmv",
        "qDY8e3WHPam4"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}